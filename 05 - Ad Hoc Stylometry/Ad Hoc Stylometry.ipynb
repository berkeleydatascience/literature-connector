{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to reproduce several findings from Emily Thornbury's<br>\n",
    "chapter \"The Poet Alone\" in her book \"Becoming a Poet in Anglo-Saxon England.\"<br>\n",
    "<br>\n",
    "In particular, see Fig 4.5 on page 170"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Python for Natural Language Processing\n",
    "<li>Strings</li>\n",
    "<li>Lists</li>\n",
    "<li>String Methods</li>\n",
    "<li>List Comprehension</li>\n",
    "\n",
    "## NLP for Literary Study\n",
    "<li>Word Frequencies</li>\n",
    "<li>Visualization</li>\n",
    "<li>Ad Hoc Stylometry</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (don't worry about understanding everything here)\n",
    "for line in open('lecture notes 09-22-15.txt'):\n",
    "    for word in line.split():\n",
    "        if word.endswith('ing'):\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"Hello, World!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = \"Hello\"\n",
    "b = 'World'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(a+b)\n",
    "print(a*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#EX. Predict what will happend when we multiply two strings\n",
    "a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "['Call', 'me', 'Ishmael']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(['Call', 'me', 'Ishmael'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list1 = ['Call', 'me', 'Ishmael']\n",
    "list2 = ['In', 'the', 'beginning']\n",
    "list3 = [1,3,5,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#EX. Predict what will happend when we perform the following operations\n",
    "print(list1+list2)\n",
    "print(list1*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list1[0])\n",
    "print(type(list1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list1[:2])\n",
    "print(type(list1[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EX. Concatenate the list1 and list2 into a single list.\n",
    "# Retrieve the third element from the combined list.\n",
    "# Retrieve the fourth through sixth elements from the combined list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "greeting = \"Hello, World!\"\n",
    "print(greeting.split())\n",
    "\n",
    "print(greeting.startswith('H'))\n",
    "print(greeting.endswith('d'))\n",
    "print()\n",
    "print(greeting.isalpha())\n",
    "print(greeting.isdigit())\n",
    "print()\n",
    "print(greeting.islower())\n",
    "print(greeting.isupper())\n",
    "print(greeting.istitle())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(greeting.lower())\n",
    "print(greeting.upper())\n",
    "print(greeting.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "greeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "greeting = greeting.lower()\n",
    "print(greeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(greeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "greeting[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EX. Return the second through eighth characters in greeting\n",
    "# Challenge: Return the characters from the first half of greeting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# List Comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[word for word in list1 if word.istitle()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EX. Concatenate the list1 and list2 into a single list.\n",
    "# Create a new list that contains only the words whose last letter is \"e\"\n",
    "# Create a new list that contains the first letter of each word.\n",
    "# Challenge: Create a new list that contains only words longer than two letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Melville - Moby Dick.txt', 'r') as file_in:\n",
    "    moby_string = file_in.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moby_tokens = moby_string.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moby_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What might we do to clean up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "moby_string = moby_string.lower()\n",
    "moby_tokens = \"\".join([char for char in moby_string if char not in string.punctuation]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moby_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "moby_dict = Counter(moby_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moby_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moby_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moby_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moby_dict.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EX. A common measure of lexical diversity for a given text is its Type-Token Ratio:\n",
    "# the average number of times each word in a text gets used.\n",
    "# Calculate the Type-Token Ratio for Moby Dick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_keys = [x[0] for x in moby_dict.most_common()]\n",
    "common_values = [x[1] for x in moby_dict.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(common_keys[:10])\n",
    "print(common_values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = sum([x for x in moby_dict.values()])\n",
    "normed_values = [x[1]/word_count for x in moby_dict.most_common()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize = (10,10))\n",
    "xticks(range(50), common_keys[:50], rotation='vertical')\n",
    "plot(normed_values[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cumulative_values = np.cumsum(normed_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize = (10,10))\n",
    "xticks(range(50), common_keys[:50], rotation='vertical')\n",
    "plot(cumulative_values[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EX. Transform the script below into a list of words, then plot their frequencies.\n",
    "# Note: A slash at the end of a line allows a string to continue unbroken onto the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = \"Man: Well, what've you got? Waitress: Well, there's egg and bacon; egg sausage and bacon; \\\n",
    "egg and spam; egg bacon and spam; egg bacon sausage and spam; spam bacon sausage and spam; \\\n",
    "spam egg spam spam bacon and spam; spam sausage spam spam bacon spam tomato and spam; \\\n",
    "spam spam spam egg and spam; spam spam spam spam spam spam baked beans spam spam spam; \\\n",
    "...or Lobster Thermidor au Crevette with a Mornay sauce served in a Provencale manner with shallots \\\n",
    "and aubergines garnished with truffle pate, brandy and with a fried egg on top and spam.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ad Hoc Stylometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('christ-and-satan.txt') as f:\n",
    "    cs_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell reproduces the series of operations performed above in the 'Visualization'\n",
    "# section, but adds one new list comprehension that approximates an analysis of alliteration\n",
    "\n",
    "cs_string = cs_text.lower()\n",
    "cs_tokens = cs_string.split()\n",
    "first_letters = [x[0] if x[0] not in ['a','e','i','o','u','y'] else 'a' for x in cs_tokens]\n",
    "allit_dict = Counter(first_letters)\n",
    "allit_freq = allit_dict.most_common()\n",
    "common_keys = [x[0] for x in allit_freq]\n",
    "common_values = [x[1] for x in allit_freq]\n",
    "normed_values = [x[1]/sum(common_values) for x in allit_freq]\n",
    "cumulative_values = np.cumsum(normed_values)\n",
    "\n",
    "figure(figsize = (10,10))\n",
    "xticks(range(len(common_keys)), common_keys, rotation='vertical')\n",
    "plot(cumulative_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs_fitts = cs_text.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cs_fitts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize = (10,10))\n",
    "for i in range(12):\n",
    "    cs_string = cs_fitts[i].lower()\n",
    "    cs_tokens = cs_string.split()\n",
    "    first_letters = [x[0] if x[0] not in ['a','e','i','o','u','y'] else 'a' for x in cs_tokens]\n",
    "    allit_dict = Counter(first_letters)\n",
    "    allit_freq = allit_dict.most_common()\n",
    "    common_keys = [x[0] for x in allit_freq]\n",
    "    common_values = [x[1] for x in allit_freq]\n",
    "    normed_values = [x[1]/sum(common_values) for x in allit_freq]\n",
    "    cumulative_values = np.cumsum(normed_values)\n",
    "    xticks(range(4), ['1st','2nd','3rd','4th'], rotation='vertical')\n",
    "    plot(cumulative_values[:4], color = plt.cm.bwr(i*.085), lw=3)\n",
    "legend(labels=['Fitt '+str(i+1) for i in range(12)], loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def allit_plotter(text):\n",
    "    from collections import Counter\n",
    "    import numpy as np\n",
    "    \n",
    "    cs_string = text.lower()\n",
    "    cs_tokens = cs_string.split()\n",
    "    first_letters = [x[0] if x[0] not in ['a','e','i','o','u','y'] else 'a' for x in cs_tokens]\n",
    "    allit_dict = Counter(first_letters)\n",
    "    allit_freq = allit_dict.most_common()\n",
    "    common_keys = [x[0] for x in allit_freq]\n",
    "    common_values = [x[1] for x in allit_freq]\n",
    "    normed_values = [x[1]/sum(common_values) for x in allit_freq]\n",
    "    cumulative_values = np.cumsum(normed_values)\n",
    "    xticks(range(4), ['1st','2nd','3rd','4th'], rotation='vertical')\n",
    "    plot(cumulative_values[:4], color = plt.cm.bwr(i*.085), lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure(figsize = (10,10))\n",
    "for i in range(12):\n",
    "    allit_plotter(cs_fitts[i])\n",
    "legend(labels=['Fitt '+str(i+1) for i in range(12)], loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# EX. Modify the script to more accurately measure alliteration. Remember: Alliteration is \n",
    "# the repetition of a sound at the beginning of two or more words in the same line.\n",
    "\n",
    "# EX. Thornbury had based part of her argument on the standard deviation of frequencies for\n",
    "# each of the most common alliterative sounds. Write a script to measure that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
